---
title: "Meta-Analyses"
output:
  html_document:
    fig_caption: yes
    theme: cerulean
    toc: yes
    toc_depth: 3
    toc_float: yes
---

[benjburgess.github.io](https://benjburgess.github.io/)

[Meta-Analyses](https://benjburgess.github.io/data/index/metaanalyses)

# Introductory Tutorial

## Introduction

As I've detailed in the [introduction to meta-analyses](https://benjburgess.github.io/metaanalyses), meta-analyses are a powerful statistical technique which collate data from multiple independent studies which address a particular research question. In doing so meta-analyses have a higher statistical power than any of the individual studies and are likely to be better able to determine the underlying trends (assuming that steps have been taken to deal with issues such as publication bias and the weighting of effect sizes). Below, I provide R code for an introductory tutorial to demonstrate how to conduct a meta-analysis on a dataset with a relatively complex structure. In doing so I outline how to account for issues such as a hierarchical random effects, covariance between studies, and fixed effects. Here, we use an ecological example outlined in more detail below.


## Question

Here, we are going to load in a dataset containing data on mean zooplankton survival under control conditions and in the presence of a pesticide. As such, we are going to conduct a meta-analysis to determine whether the pesticide affects zooplankton survival. Now I've generated this data, but for the purposes of this tutorial we are goint to assume that it is *'real world'* data. We are going to assume that experiments were really conducted and that this dataset has been put together by someone following a comprehensive literature search. The dataset comprises data on the experiments (means, standard deviations, and sample sizes) and meta-data on the study authors, location of study (region and lake), and the intensity of the pesticide which the stressor used. For this tutorial, we are going to go conduct a thorough meta-analysis using this dataset.

To reiterate, here we are going to use this dataset to conduct a meta-analysis to determine whether the pesticide affects zooplankton survival.

## Packages

First of all lets get the packages we need for this analysis loaded. This analysis only requires us to load in two packages - `ggplot2` & `metafor` [(Viechtbauer, 2010)](https://www.jstatsoft.org/article/view/v036i03). The metafor package is the gold standard for meta-analytical software and has a variety of options and functions which make conducting a meta-analysis relatively simple.

```{r class.source = "bg-info", message=FALSE, warning=FALSE}
library(metafor)
library(ggplot2)
```

## Data

The next thing we need to do is load in the data we are going to be analysing. 
This data is available via [github](https://github.com/benjburgess/i/blob/master/Data/MetaAnalysis_Pesticide_Data.RData) for anyone wanting to replicate this analysis.
Just to reiterate, I have generated this data for this example analysis, it is not *real world* data.

```{r class.source="bg-info", class.output="bg-success"}
df2 <- read.csv("~/R_sandbox/Meta_Analysis_Lake.csv")
```

Let's have a look at the data we have here.

```{r class.source="bg-info", class.output="bg-success"}
head(df2, n= 36)
```

So our dataset comprises 13 different variables as follows:

Index - A unique identifer for each row
Author - The lead author of each study from which the data has been collated
Region - The region from which the study organisms were collected (North, East, or South)
Lake   - The lake from which the study organisms were collected (A - K) - note that this is nested within region
Intensity - The concentration of the pesticide used in the different studies. Rather than a numeric value, this is a categorical variable (Low, Medium, High)
Treatment_N - $N_{t}$ - The number of replicates for the treatment group in each experiment.
Control_N - $N_{c}$ - The number of replicates for the control group in each experiment.
Control_Mean - $X_{c}$ - The mean survival (across all replicates) for the control group in each experiment.
Control_SD - $SD_{c}$ - The standard deviation for the mean of the control group (calculated using all replicates).
Treatment_Mean - $X_{t}$ - The mean survival (across all replicates) for the treatment group in each experiment.
Treatment_SD - $SD_{t}$ - The standard deviation for the mean of the treatment group (calculated using all replicates).
Notes - Notes on the each experiment - Note that this is NA for all rows accept the final two rows.

We have all the raw data we need for our meta-analysis here, but what we need to do now is calculate effect sizes for each experiment which will then be amalgamated within the meta-analysis. For this analysis we will be using the response ratio [(Lajeunesse, 2011)](https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/11-0423.1).

For our analysis, we are seeking to determine whether the pesticide affects zooplankton survival. As such we can calcualte the response ratio and compare the mean survival of the control ($X_{c}$) and treatment ($X_{t}$) groups using the following equation.

$RR = \log(\frac{X_{t}}{X_{c}})$

For our analysis, if $RR$ = 0 then there is no difference between the survival of zooplankton in the control and treatment groups. If $RR$ < 0, then zooplaknton survival is greater for the control group than the treatment group. If $RR$ > 0, then zooplaknton survival is greater for the treatment group than the control group.

However, for each of our experiments, there is an associated uncertainty (i.e., standard deviation) which means that we likewise have some uncertainty in the value of the $RR$. Accordingly, for each experiment we can calculate the variance ($Var_{RR}$) for each value of $RR$ using the following equation.

$Var_{RR} = \frac{(SD_{c})^2}{N_{c} \cdot (X_{c})^2} + \frac{(SD_{t})^2}{N_{t} \cdot (X_{t})^2}$

Here, the variance is calculated using the standard deviation, sample sizes, and means for the control and treatment groups. For more information on this calculation, see [Lajeunesse (2011)](https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/11-0423.1).

The code to calculate both $RR$ and $Var_{RR}$ is shown below.

```{r class.source="bg-info", class.output="bg-success"}
df2$RR <- log(df2$Treatment_Mean/df2$Control_Mean)

df2$Var_RR <- (df2$Control_SD^2)/(df2$Control_N*(df2$Control_Mean^2)) + 
         (df2$Treatment_SD ^2)/(df2$Treatment_N*(df2$Treatment_Mean^2))
```

As I alluded to above, we can determine how the pesticide affects zooplankton survival based on the value of $RR$. However, the uncertainty (i.e., $Var_{RR}$) in our estimate of $RR$ means that we may be unable to confirm whether our interpretation of $RR$ is correct (i.e., statistically significant). To determine whether we have statistically signficant confidence in our results we can calculate confidence intervals for each of values of $RR$. 95% confidence intervals can be calculated using the following equation.

$CI_{RR} = 1.96 * \sqrt{Var_{RR}}$

Accordingly, upper and lower 95% confidence intervals can be calculated as $RR + CR_{RR}$ & $RR - CR_{RR}$ respectively.

The interpretation of $RR$ and confidence intervals is relatively simple. If $RR$ is negative and the confidence intervals do not overlap 0, then there is a statistically significant difference between the control and treatment groups (the pesticide reduces zooplankton survival).  If $RR$ is positive and the confidence intervals do not overlap 0, then there is a statistically significant difference between the control and treatment groups (the pesticide increases zooplankton survival). If the confidence intervals overlap 0, then there is no statistically significant difference between the control and treatment groups, it does not matter if $RR$ is positive or negative in this scenario. 
To visualise our dataset, we can plot the values of $RR$ with their respective confidence intervals using the following code.

```{r class.source="bg-info", class.output="bg-success"}
ggplot(df2, aes(x=Index, y=RR)) + 
    geom_hline(yintercept=0, col= "red", linetype="dashed") +
    geom_errorbar(aes(ymin=RR-(1.96*sqrt(Var_RR)), ymax=RR+(1.96*sqrt(Var_RR))), width=.1) +
    geom_point() +
    theme_bw()
```

As we can see, the vast majority of $RR$ efect sizes have confidence intervals which overlap zero. Meaning that most experiments do not observe a statistically significant difference between the survival of zooplankton in the control and treatment groups. 

Overall, the aim of a meta-analysis is to combine data from multiple different experiments or studies to determine the overarching trends across these studies by combining them and increasing the statistical power of the analysis.

At this point, we can move on to conduct the meta-analysis.


## Meta-analyses

At this point we are going to walk through the various different steps to create the most statistically rigourous meta-analytical model for our dataset.

Now, the simplest meta-analytical model we could is as follows. Here, we provide our effect sizes ($RR$) to the *yi* variable and effect size variances ($Var_{RR}$) to the *V* variable.

What the metafor model is doing here is combining all the different effect sizes ($RR$) but weighting them by the inverse of the effect size variance ($Var_{RR}$). Weighting effect sizes is highly recommended in meta-analyses as it helps prevent biases from occurring. Here, by weighting effect sizes by the inverse of the effect size variance we are say that we want those effects which we have more confidence in (i.e., lower effect size variances) to be given a higher weighting in our model. This helps the meta-analysis from being overly influenced by those effect sizes which we have lower confidence in and ultimately leads more robust results.

We can run the meta-analysis using the following code using the rma.mv function from the metafor package.


```{r class.source="bg-info", class.output="bg-success"}
rr.ma0 <- rma.mv(yi = RR, 
                 V = Var_RR, 
                 data = df2)

rr.ma0
```

So, lets interpret our results. Our meta-analytical model finds that for our dataset, the summary effect size (i.e., combined $RR$ values from all experiments) is `r as.numeric(rr.ma0$b)`. Futhermore, the lower (`r as.numeric(rr.ma0$ci.lb)`) and upper (`r as.numeric(rr.ma0$ci.ub)`) confidence intervals for our summary effect size do not overlap zero. As such, our model suggests that the pesticide results in a statistically significant reduction in zooplankton survival. 

However, this is the simplest meta-analytical we can fit to our dataset, but it is not necessarily appropriate for our dataset. Indeed, for the vast majority of datasets a meta-analytical model this simple would not be appropriate.

To start, let's check the notes for our dataset that we ignored earlier.
```{r class.source="bg-info", class.output="bg-success"}
print(df2$Notes)
```

The notes for our dataset tell us that the same control group (and therefore same values of control mean,  treatment and sd) have been used across two experiments.

Let's check our dataset to see.

```{r class.source="bg-info", class.output="bg-success"}
tail(df2, n=2)
```

Indeed, we can see that this is indeed the case, with the Control_Mean, Control_SD, and Control_N values being the same across rows 35 and 36. This is an issue as it means that the different experiments in our dataset are not numerically independent as the above meta-analytical model was assuming. As such, this introduces issues with covariance into our dataset, (i.e., a single control mean affects two $RR$ values). However, we can account for this in our dataset by implementing a covariance-variance matrix. While this sounds complex it is relatively straight-forward. Rather than having a simple list of the 36 effect size variances that we had before, we change to having a matrix which is 36 rows by 36 columns. Here all the values in matrix are 0 except for the major diagonal which has the corresponding value of the effect size variance. For instance see the following example. 

$$Example\ Covariance\ Variance\ Matrix = \begin{pmatrix}
Var_{RR}[1] & 0 & 0\\
0 & Var_{RR}[2] & 0\\
0 & 0 & Var_{RR}[3]\\
\end{pmatrix}$$

Here, the major diagonal represents the effect size variances and the off diagonals represent the covariance between two effect sizes. Accordingly, if two values of $RR$ share a control, then the off-diagonals will be non-zero due to the covariance. In the following example $RR$ 2 and 3 share a control, hence the values of the matrix in positions (2,3) and (3,2) are non-zero and both have the same value.

$$Example\ Covariance\ Variance\ Matrix = \begin{pmatrix}
Var_{RR}[1] & 0 & 0\\
0 & Var_{RR}[2] & CovVar_{RR}(2,3)\\
0 & CovVar_{RR}(2,3) & Var_{RR}[3]\\
\end{pmatrix}$$

Now the calculation of the effect size covariance is relatively straightforward. It is the same as the equation for effect size variance, except that it only considers the terms which are the same across the two values of $RR$. As such, if two experiments share a control then the covariance between the two corresponding $RR$ can be calculated as:

$CovVar_{RR} = \frac{(SD_{c})^2}{N_{c} \cdot (X_{c})^2}$

So, now that we know that we need to account for covariance in our dataset, we can generate a covariance variance matrix using the following code:

```{r class.source="bg-info", class.output="bg-success"}

cov_var <- matrix(0, nrow = 36, ncol = 36)

diag(cov_var) <- df2$Var_RR

cov_var[35, 36] <- cov_var[36, 35] <- (df2$Control_SD[36]^2)/(df2$Control_N[36]*(df2$Control_Mean[36]^2))
```

Using the above code we have generated a covariance variance matrice where the major diagonal is equal to the values of $Var_{RR}$ and all off-diagonals are 0 except for positions (35,36) and (36,35) which have the same value of covariance.

We can check this using the following code, just foccusing on the bottom right corner of the matrix.

```{r class.source="bg-info", class.output="bg-success"}
cov_var[c(33:36), c(33:36)]
```

So, now that we have generated the covariance variance matrix we can input it into our meta-analytical model using the following code.

```{r class.source="bg-info", class.output="bg-success"}
rr.ma1 <- rma.mv(yi = RR, 
                 V = cov_var, 
                 data = df2)

rr.ma1
```

So, lets interpret our results. Our new meta-analytical model finds that for our dataset, the summary effect size (i.e., combined $RR$ values from all experiments) is `r as.numeric(rr.ma1$b)`. Futhermore, the lower (`r as.numeric(rr.ma1$ci.lb)`) and upper (`r as.numeric(rr.ma1$ci.ub)`) confidence intervals for our summary effect size do not overlap zero. As such (as before), our model suggests that the pesticide results in a statistically significant reduction in zooplankton survival. Our results very slightly differ to the meta-analytical model without the covariance-variance matrix. However, this is still very important to introduce into our analysis as if more experiments were covarying our results might be drastically altered by acccounting for covariance.

However, this model still isn't appropriate for our dataset. As mentioned right at the very start of our analysis, our dataset comprises data collected from various regions and lakes. Let's check this using the following code.

```{r class.source="bg-info", class.output="bg-success"}
for(i in unique(df2$Region)){
  
  print(i)
  
  print(unique(subset(df2, Region == i)$Lake))
  
  print("---")
}
```

As we can see, our dataset comprises data from three regions and then *within* each region a number of different lakes. As such, our dataset contains a hierarchical structure which we need to take into account. 

We need to consider whether the region and lakes are potentially influencing our results. For example, we might expect that experiments in the same region are more similar to each other than those in different regions. Likewise, we would probably expect that experiments in the same lake are more similar to each other than those in different lakes.
As such, there may be random effects associated with each region and each lake that might be influencing our results. Accordingly, we can take the effect of region and lake into account by incorporating random effects in the meta-analytical models.

Here, we include a term 'random' in the model. In doing so we use the form of `random ~ 1 | Region/Lake`. Here, the main thing to note is that we are specifying that we want to take into account random effects for Lake *within* Region. We do this as (in line with what we've discussed) lake is nested within region.

As such, we can run our new meta-analytical model using the following code.


```{r class.source="bg-info", class.output="bg-success"}
rr.ma2 <- rma.mv(yi = RR, 
                 V = cov_var, 
                 random = ~ 1 | Region/Lake,
                 data = df2)

rr.ma2
```

So, lets interpret our results. Our new meta-analytical model finds that for our dataset, the summary effect size (i.e., combined $RR$ values from all experiments) is `r as.numeric(rr.ma2$b)`. Futhermore, the lower (`r as.numeric(rr.ma2$ci.lb)`) and upper (`r as.numeric(rr.ma2$ci.ub)`) confidence intervals for our summary effect size *do*  overlap zero. As such, once we have taken into account the random effects of Lake and Region, our model suggests that the pesticide does not result in a statistically significant reduction in zooplankton survival. This illustrates the importance of accounting for potential sources of variation within our meta-analytical models, as it appears as though the random effects due to region and lake may have dictating previous results.

However, we also have another potential source of variation to consider is that the data comes from numerous different papers (shown by the *Author* variable). As such, we can add an extra random effect to our meta-analytical model for Author (i.e., paper which provided the data). As for Region and Lake, the assumption here is that data from the same paper is likely to be more similar than data from different papers.

As such, we can run our new meta-analytical model using the following code.

```{r class.source="bg-info", class.output="bg-success"}
rr.ma2i <- rma.mv(yi = RR, 
                 V = cov_var, 
                 random = list(~ 1 | Region/Lake, ~1|Author),
                 data = df2)

rr.ma2i
```

So, lets interpret our results. Our new meta-analytical model finds that for our dataset, the summary effect size (i.e., combined $RR$ values from all experiments) is `r as.numeric(rr.ma2i$b)`. Futhermore, the lower (`r as.numeric(rr.ma2i$ci.lb)`) and upper (`r as.numeric(rr.ma2i$ci.ub)`) confidence intervals for our summary effect size *do*  overlap zero. As such, once we have taken into account the random effect Author (i.e., paper) alongside Lake and Region, our model suggests that the pesticide does not result in a statistically significant reduction in zooplankton survival. This illustrates the importance of accounting for *all* the potential sources of variation within our meta-analytical models, as it appears as though the random effect due to Author may account for even more variation than region and lake.

In theory, we could stop our analysis at this point. The model we have build is in theory appropriate for our dataset. However, we also have the option of considering various different fixed effects. In other words, determining whether the effect of pesticide on zooplankton survival varies across fixed groups for variable. One further analysis we could conduct is considering whether the effect of pesticide varies with its intensity. Let's have a look again at the Intensity column of our dataset.


```{r class.source="bg-info", class.output="bg-success"}
print(df2$Intensity)
```

As we can see, we have three different levels in our dataset corresponding to Low, Medium, and High intensity levels for the pesticide. As such, we could instruct the meta-analytical model to consider the different intensities using the *mods* parameter. Here we include the following line `mods = ~ Intensity -1`, which instructs the model to split the effect of pesticide by its intensity, with the `-1` saying to not plot an intercept for our models.

As such, we can run the model using the following code.



```{r class.source="bg-info", class.output="bg-success"}
rr.ma3 <- rma.mv(yi = RR, 
                 V = cov_var,
                 mods = ~ Intensity -1,
                 random = list(~ 1 | Region/Lake, ~1|Author),
                 data = df2)

rr.ma3
```

So, lets interpret our results. Our new meta-analytical model finds that for our dataset, the summary effect size (i.e., combined $RR$ values from all experiments) is -0.0005 for low pesticide intensities, `r as.numeric(rr.ma3$b[3])` for medium pesticide intensities, and `r as.numeric(rr.ma3$b[1])` for high pesticide intensities. Additionally, we can see that the confidence intervals for the low and medium pesticide intensities overlap zero, meaning that there is no statistically significant difference in zooplankton survival for the control and treatment groups for the low and medium pesticide intensities. However, for the high intensity of pesticides the confidence intervals do not overlap zero, indicating that high intensities of the pesticide have a statistically significant effect on zooplankton survival. 

If we focus on the high intensity of pesticide, the summary effect size of `r as.numeric(rr.ma3$b[1])` (and confidence intervals that don't overlap zero) indicates that high pesticide intensities have a strong negative effect on zooplankton survival. This finding may be crucial, as until we used the fixed effect of intensity it appeared as though the pesticide did not have a statistically significant effect on zooplankton survival. However, this final analysis has shown that high intensities of the pesticide negatively affect zooplankton survival while no such effect was observed for the low and medium pesticide intensities.

## Concluding remarks

Overall, this tutorial comprises an introduction to how meta-analyses can be conducted for relatively complex datasets. Here, we address concepts such as effect size calculation, covariance, hierarchical random effects, and fixed effects. This tutorial shows an effective meta-analysis and the considerations that need to be made, alongside tips for ensuring a rigourous analysis. 

The tutorial here only covers the basics, and it is always prudent to consider additional measures such as heterogeneity (e.g., $I^2$), variance components (see above model results), and various model diagonistics (e.g., DFBETAs, Cooks' D, and $\hat{R}$). Furthermore, this tutorial hasn't covered one of the hardest and most time-consuming aspects of a meta-analysis.... the collation of the dataset! If that is what you are currently looking for advice on, I'd point you towards some great R packages such as `juicr` [(Lajeunesse, 2021)](https://cran.r-project.org/web/packages/juicr/vignettes/juicr_basic_vignette_v0.1.pdf).

Overall, this is hopefully a useful introductory guide to performing a meta-analysis and helps you to avoid some of the many traps that many people fall into when doing a meta-analysis!


## References

Lajeunesse, M. J. (2011). On the meta-analysis of response ratios for studies with correlated and multi-group designs. *Ecology*, 92(11), 2049-2055.

Lajeunesse, M.J. (2021) Squeezing data from scientific images with the juicr package for R. R package, *v.0.1. CRAN*

Viechtbauer, W. (2010). Conducting meta-analyses in R with the metafor package. *Journal of Statistical Software*, 36(3), 1-48.

## Links

[benjburgess.github.io](https://benjburgess.github.io/)

[Support Vector Machines](https://benjburgess.github.io/data/index/svm)